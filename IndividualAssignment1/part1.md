# ðŸ“š Week 1 Summary: The Web as a Source of Knowledge

## ðŸŒ Theme 1: The Web as a Vast and Complex Knowledge Base

The web is not just a collection of documentsâ€”itâ€™s a rich, sprawling **ecosystem of structured, semi-structured, and unstructured information**. Understanding its nature is critical to leveraging it for knowledge extraction.

- **Heterogeneity of the Web**: Content varies widely in syntax, format, language, structure, and quality.
- **Types of Web Content**:
  - *Unstructured*: Natural language text.
  - *Semi-structured*: HTML, tables, tagged elements.
  - *Structured*: Databases, schema.org annotations, Linked Data.
- **Surface vs. Deep Web**:
  - Surface Web: Indexed by search engines.
  - Deep Web: Hidden behind forms or dynamic content.
- **Challenges in Extraction**: Inconsistency, duplication, dynamic content, and multilingualism make automation hard.

> ðŸ§  Key Idea: To extract knowledge from the web, we must **embrace its diversity** while finding ways to structure chaos.

---

## ðŸ§  Theme 2: Knowledge Representation on the Web

To transform web data into actionable insights, it must be **modeled and represented in structured formats**, enabling machine interpretation.

- **Knowledge Bases (KBs)**: Store facts in structured form (e.g., subjectâ€“predicateâ€“object triples).
- **Ontologies**:
  - Define shared vocabularies, concepts, and relationships.
  - Enable semantic alignment across diverse datasets.
- **Schema.org & RDF**:
  - Schema.org: Vocabulary for embedding structured metadata in web pages.
  - RDF (Resource Description Framework): Standard model for data interchange on the web.
- **Knowledge Graphs (KGs)**:
  - Extend KBs by emphasizing relationships and graph-based reasoning.

> ðŸ§  Key Idea: The power of web-scale extraction lies in its ability to **translate messy content into interconnected, semantically meaningful structures**.

---

## ðŸ§° Theme 3: Tools, Infrastructure, and Techniques for Knowledge Harvesting

Building large-scale knowledge systems from the web requires robust **tools, frameworks, and methodologies**.

- **Crawling & Indexing**:
  - Web crawlers collect documents; indexers organize content for search and extraction.
- **Information Extraction (IE)**:
  - Techniques include named entity recognition, relation extraction, and coreference resolution.
- **OpenIE vs. Traditional IE**:
  - *OpenIE*: Extracts relations from text without requiring a predefined schema.
  - *Traditional IE*: Requires domain-specific patterns and supervision.
- **Entity Linking & Disambiguation**: Match mentions in text to canonical entries in a KB (e.g., Wikipedia).

> ðŸ§  Key Idea: The web is only valuable as a knowledge resource when supported by **scalable, intelligent extraction and linking techniques**.

---
